Mini Project: IT Asset Data Operations & Insights
Overview

This project provides hands-on experience in data engineering and analytics workflows — from cleaning raw data, indexing it into Elasticsearch, transforming and enriching it using Python, to building meaningful business insights through visualizations in Kibana.

The dataset simulates real-world enterprise IT asset management challenges and develops skills in data wrangling, transformation, and analytical reporting.

Dataset

File Name: it_asset_inventory_enriched.csv

Each record represents an IT asset with details such as hostname, country, provider, operating system, lifecycle status, installation date, and other operational attributes.

Phase 1 — Excel Data Cleaning
Objective

Clean the dataset in Excel and prepare it for ingestion into Elasticsearch.

Tasks Performed

Removed duplicate rows based on the hostname field

Used: Data → Remove Duplicates

Trimmed extra spaces from text fields

Formula used: =TRIM(A2)

Handled blanks and missing values

Replaced empty cells with "Unknown"

Checked and standardized date formats in operating_system_installation_date

Ensured consistent YYYY-MM-DD format

Saved the cleaned dataset as it_asset_inventory_cleaned.csv

Output

A clean and structured CSV file ready for indexing into Elasticsearch.

Phase 2 — Indexing Data to Elasticsearch Using Python
Objective

Write a Python script to load the cleaned CSV data into Elasticsearch.

Script Used

index_data.py

Steps Performed

Created a .env file to securely store Elastic Cloud URL and API Key.

Connected to Elasticsearch Cloud using the elasticsearch and python-dotenv libraries.

Loaded the cleaned CSV using pandas.

Indexed the records into an index named it-assets using the Elasticsearch Bulk API.

Verified successful indexing by checking document count and sample data in Kibana.

Libraries Used
pandas
elasticsearch
python-dotenv

Output

Data successfully indexed into Elasticsearch and available for visualization in Kibana.

Phase 3 — Data Transformation and Enrichment
Objective

Enhance the indexed data using Elasticsearch scripting and transformations.

Script Used

transform_data.py

Steps Performed

Reindexed Data:
Copied data from it-assets to a new index named it-assets-transformed.

Added Derived Field (risk_level):

risk_level = "High" if operating_system_lifecycle_status in ["EOL", "EOS"] else "Low"


EOL (End of Life) or EOS (End of Support) systems are marked as high risk.

Calculated System Age:
Computed in years based on operating_system_installation_date.

Deleted Invalid Records:
Removed entries missing hostnames or having the provider marked as "Unknown".

Updated Enriched Data:
Used _update_by_query to apply new fields to existing records in Elasticsearch.

Output

The transformed and enriched dataset is stored in the index it-assets-transformed.

Phase 4 — Visualization and Insights
Objective

Build visualizations and generate business insights using Kibana.

Visualizations Created

Assets by Country

Lifecycle Status Distribution

High vs. Low Risk Assets

Top Operating System Providers

Screenshots

All visualization screenshots are saved in the folder:

visualization_screenshots/

Business Insights

Approximately 40% of assets are EOL or EOS, indicating an urgent need for OS upgrades in countries such as India and Brazil.

Low-risk assets are primarily associated with modern and supported operating systems.

A small number of providers contribute to a majority of deployed systems, suggesting dependency on key vendors.

Systems older than five years show higher vulnerability levels, highlighting the importance of lifecycle management.